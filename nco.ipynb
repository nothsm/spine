{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d74471",
   "metadata": {},
   "source": [
    "# Neural Combinatorial Optimization with Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3929833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from typing import NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe710584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0.597640340831, 0.811472963882), (0.378392540696, 0.188165799059), (0.442849630371, 0.291815169363), (0.363774192611, 0.596244647907), (0.955211930984, 0.947031856076)], [(0.616748732984, 0.862917265096), (0.646589030772, 0.211572180783), (0.6699398908, 0.475991557189), (0.339816729613, 0.391328128102), (0.470564513088, 0.253927406768)], [(0.379029510454, 0.89044636514), (0.322733898909, 0.282491575172), (0.823656482117, 0.667439553234), (0.585094717207, 0.99053909902), (0.402746680674, 0.185903231104)], [(0.533507548416, 0.330254568654), (0.243859093733, 0.0967704629894), (0.495618769035, 0.133439606782), (0.864499913366, 0.0215000093345), (0.959150495268, 0.210120768216)], [(0.853260610499, 0.868294134879), (0.247799099468, 0.914311342122), (0.953245545818, 0.291880778407), (0.310663329268, 0.805399919393), (0.50384588427, 0.0561969841645)]]\n",
      "[[1, 4, 2, 3, 5, 1], [1, 3, 2, 5, 4, 1], [1, 2, 5, 3, 4, 1], [1, 2, 3, 4, 5, 1], [1, 2, 4, 5, 3, 1]]\n",
      "[[(0.0293917945835, 0.00964773810843), (0.367719666527, 0.0106191137455), (0.694157200237, 0.303067391838), (0.724765619752, 0.671382093482), (0.27330556367, 0.955392355916)], [(0.528447058132, 0.723820349021), (0.760590431168, 0.572962812756), (0.106977584004, 0.160785774948), (0.346606404914, 0.465129584674), (0.696204794697, 0.375925633357)], [(0.946990807756, 0.033076970984), (0.906251695035, 0.33310360808), (0.867709892367, 0.0504619847148), (0.258794395549, 0.885420519511), (0.0660963526887, 0.103315392368)], [(0.851153523028, 0.739943154728), (0.960355753147, 0.596362425032), (0.930038258598, 0.10717940006), (0.54971316001, 0.956029334878), (0.262190562822, 0.501427279828)]]\n",
      "[[1, 2, 3, 4, 5, 1], [1, 2, 5, 3, 4, 1], [1, 3, 5, 4, 2, 1], [1, 4, 5, 3, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "TSP5_TRAIN_FILE = 'data/tsp/tsp_5_train/tsp5.txt'\n",
    "TSP5_TEST_FILE  = 'data/tsp/tsp_5_train/tsp5_test.txt'\n",
    "\n",
    "TRAIN_LEN = 8\n",
    "TEST_LEN  = 4\n",
    "\n",
    "xs_train = []\n",
    "ys_train = []\n",
    "with open(TSP5_TRAIN_FILE, 'r') as f: # TODO: How is this implemented?\n",
    "    for _ in range(TRAIN_LEN): # TODO: check the file has enough lines\n",
    "        line = f.readline() # TODO: How is this implemented?\n",
    "        x_str, y_str = line.strip().split(' output ')\n",
    "        x_words = x_str.split(' ')\n",
    "        y_words = y_str.split(' ')\n",
    "        x = [(float(x_words[i]), float(x_words[i + 1])) for i in range(0, len(x_words), 2)] # warning: complexity\n",
    "        y = [int(word) for word in y_words]\n",
    "        xs_train.append(x)\n",
    "        ys_train.append(y)\n",
    "\n",
    "# TODO: Get validation data\n",
    "\n",
    "xs_test = []\n",
    "ys_test = []\n",
    "with open(TSP5_TEST_FILE, 'r') as f:\n",
    "    for _ in range(TEST_LEN):\n",
    "        line = f.readline()\n",
    "        x_str, y_str = line.strip().split(' output ')\n",
    "        x_words = x_str.split(' ')\n",
    "        y_words = y_str.split(' ')\n",
    "        x = [(float(x_words[i]), float(x_words[i + 1])) for i in range(0, len(x_words), 2)]\n",
    "        y = [int(word) for word in y_words]\n",
    "        xs_test.append(x)\n",
    "        ys_test.append(y)\n",
    "\n",
    "tsp5_train = list(zip(xs_train, ys_train))\n",
    "tsp5_test  = list(zip(xs_test, ys_test))\n",
    "\n",
    "print(xs_train[:5])\n",
    "print(ys_train[:5])\n",
    "print(xs_test[:5])\n",
    "print(ys_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1dda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size    = 128   # mini-batches of 128 sequences\n",
    "batch_size    = 1\n",
    "input_dim     = 2     # D: euclidean tsp for R^2\n",
    "seq_len       = 5     # L: tsp5\n",
    "hidden_dim    = 128   # H: lstm cells with 128 hidden units\n",
    "embed_dim     = 128   # E: embed the two coordinates of each point in a 128-dimensional space\n",
    "lr            = 1e-3  # use an initial lr of 10^-3 on TSP20, TSP50. use 10^-4 on TSP100\n",
    "lr_decay_step = 5000  # that we decay every 5000 steps\n",
    "lr_decay_rate = 0.96  # by a factor of 0.96\n",
    "n_glimpses    = 0     # TODO: Increase this\n",
    "n_epochs      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [ ] Do I setup model config first, or setup dataset first?\n",
    "# - [ ] Play with rnn activation function (relu vs tanh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
