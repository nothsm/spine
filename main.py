import math
import time
from functools import partial
from typing import Any, Callable, TypedDict, Optional

import mlx.core as mx
from mlx.utils import tree_map
import numpy as np
import numpy.typing as npt

# --------------------------------- constants ----------------------------------

N_TRAIN = 32
N_TEST = 8

# -------------------------------- type alias ----------------------------------

Array = mx.array
NPArray = npt.NDArray[Any]  # TODO: tighten this
Dataset = tuple[NPArray, NPArray, NPArray, NPArray]
ModelParams = dict[Any, Any]
ModelForward = Callable[..., Any]

# ---------------------------------- datasets ----------------------------------

# TODO: Think about the ordering of the parameters

def load_bixor(n_samples: int = 32) -> Dataset: ...


# TODO: Return a dict here?
def load_donut(n_train: int = N_TRAIN, n_test: int = N_TEST, r: float = 0.5) -> Dataset:
    X_train = np.random.uniform(-1, 1, size=(n_train, 2))
    y_train = np.array(
        [1.0 if math.sqrt(x0**2 + x1**2) < r else -1.0 for x0, x1 in X_train.tolist()]
    )
    X_test = np.random.uniform(-1, 1, size=(n_test, 2))
    y_test = np.array(
        [1.0 if math.sqrt(x0**2 + x1**2) < r else -1.0 for x0, x1 in X_test.tolist()]
    )
    return X_train, y_train, X_test, y_test


# pre: true_params should be generated by something like np.random.normal(size=(input_dim,))
def load_regression(
    true_params, n_train: int = N_TRAIN, n_test: int = N_TEST, input_dim: int = 2
) -> Dataset:
    eps_train = 1e-2 * np.random.normal(size=(n_train,))
    X_train = np.random.normal(size=(n_train, input_dim))
    y_train = (X_train @ true_params) + eps_train

    eps_test = 1e-2 * np.random.normal(size=(n_test,))
    X_test = np.random.normal(size=(n_test, input_dim))
    y_test = (X_test @ true_params) + eps_test

    return X_train, y_train, X_test, y_test


def load_tanh(
    true_params, n_train: int = N_TRAIN, n_test: int = N_TEST, input_dim: int = 2
) -> Dataset:
    X_train, y_train, X_test, y_test = load_regression(
        true_params=true_params, n_train=n_train, n_test=n_test, input_dim=input_dim
    )
    y_train, y_test = np.tanh(y_train), np.tanh(y_test)
    return X_train, y_train, X_test, y_test

# TODO
def load_tsp5(file: Optional[str] = 'data/tsp/tsp_5_train/tsp5.txt') -> Dataset:
    ...


def load_sincos(n_samples=32): ...


# ---------------------------------- models ------------------------------------


# TODO: Support bias
class RNNCell(TypedDict):
    wx: Array
    wh: Array


def rcnew(input_dim: int, hidden_dim: int) -> RNNCell:
    assert input_dim > 0

    wx = 1e-2 * mx.random.normal(shape=(input_dim,))  # TODO: Use better init
    wh = 1e-2 * mx.random.normal(shape=(hidden_dim, hidden_dim))
    return RNNCell(wx=wx, wh=wh)


def rcinit(cell: RNNCell, wx: Array, wh: Array):
    cell["wx"] = mx.array(wx)
    cell["wh"] = mx.array(wh)


# TODO: Play with this activation
# Note: If any of the entries is large, tanh makes it go to 1
def rcfwd(cell: RNNCell, xt: Array, hprev: Optional[Array] = None) -> Array:
    wx = cell["wx"]
    wh = cell["wh"]

    if hprev is None:
        hprev = mx.zeros(wh.shape[0])  # TODO: how does this interact with compilation?

    ht = mx.tanh(xt @ wx + hprev @ wh)  # TODO: Why are the matmuls transposed?
    return ht

def rcclassify(cell: RNNCell, xt: Array, hprev: Optional[Array] = None) -> Array:
    assert cell['wh'].shape[0] == 1
    ...

# TODO
def rcbwd(cell, dht, cache): ...


class RNN(TypedDict):
    cell: RNNCell


def rnnnew(input_dim: int, hidden_dim: int) -> RNN:
    cell = rcnew(input_dim=input_dim, hidden_dim=hidden_dim)
    return RNN(cell=cell)


# TODO
# TODO: Might return a tuple of arrays
def rnnfwd(rnn: RNN, xs: Array, h0: Array) -> Array:
    y, h = ...
    return y, h


# TODO
class RNNEncoder(TypedDict): ...


# TODO
class RNNDecoder(TypedDict): ...


# TODO
class RNNPointerNet(TypedDict): ...


# TODO
class MyNCO(TypedDict):
    embedding: npt.NDArray[np.float32]
    actor_net: RNNPointerNet


# TODO: I don't think I need Attention, PointerNet for just using RNN's?

# TODO
class Encoder(TypedDict): ...


# TODO
class Attention(TypedDict): ...


# TODO
class Decoder(TypedDict): ...


# TODO
class PointerNet(TypedDict): ...


# TODO
class NCO(TypedDict): ...


# ----------------------------- optimizers/solvers -----------------------------


class MySGD(TypedDict):
    lr: float


def sgdnew(lr: float) -> MySGD:
    return MySGD(lr=lr)


# TODO: Should I make this private?
def sgdupdate1(sgd: MySGD, param: Array, grad: Array) -> Array:
    lr = sgd["lr"]
    return param - lr * grad


def sgdupdate(sgd: MySGD, params: Array, grads: Array) -> Array:
    return tree_map(lambda param, grad: sgdupdate1(sgd, param, grad), params, grads)


# TODO: How do I make it so I can pass in the loss function?
def sgdsolve(
    sgd: MySGD,
    model: tuple[ModelForward, ModelParams],
    X: Array,
    y: Array,
    batch_size: int,
    n_epochs: int = 10,
    print_every: Optional[int] = None,
):
    fwd, params = model
    mx.eval(params)

    # pre: ypreds.shape == y.shape
    def mse(params, X, y):
        ypreds = fwd(params, X)
        loss = (ypreds - y).square().mean()
        return loss 

    loss_and_grad_fn = mx.value_and_grad(mse)

    @mx.compile
    def step(params, X, y):
        loss, grads = loss_and_grad_fn(params, X, y)
        params = sgdupdate(sgd, params, grads)
        return params, loss

    def batch_iterate(batch_size, X, y):
        perm = mx.array(np.random.permutation(y.size))
        for i in range(0, y.size, batch_size):
            ixs = perm[i : i + batch_size]
            yield X[ixs], y[ixs]

    steps = 0
    metrics = {'loss': [], 'dt': []}
    for e in range(n_epochs):
        for xi, yi in batch_iterate(
            batch_size, X, y
        ):  # TODO: Doesn't this have overhead?
            tic = time.perf_counter_ns()
            params, loss = step(params, xi, yi)
            mx.eval(loss, params)
            toc = time.perf_counter_ns()

            steps += 1

            step_loss = loss.item()
            step_dt = toc - tic
            metrics['loss'].append(step_loss)
            metrics['dt'].append(step_dt)
            if print_every and (steps % print_every) == 0:
                print(
                    f"step: {steps} | epoch: {e} | loss: {step_loss:.5f} | dt: {step_dt}ns"
                )
    return params, metrics


# TODO
class MyAdam(TypedDict): ...


# TODO
def adamnew(): ...


# TODO
def adamupdate(adam): ...


# TODO
class MyMuon(TypedDict): ...


# TODO
def muonnew(muon): ...


# TODO
class MyLRScheduler(TypedDict): ...




# -----------


# TODO
def reward(solution): ...


def main():
    print("Hello from spine!")


if __name__ == "__main__":
    main()

# TODO:
# - [ ] Add shebang to use current uv environment
# - [ ] Implement data/tsp/prepare.py
# - [ ] Implement data/ARC-AGI/prepare.py
# - [ ] Implement data/ARC-AGI-2/prepare.py
# - [ ] Implement or find supervised learning baseline
# - [ ] Implement or find Christofides baseline
# - [ ] Implement or find OR-Tools baseline
# - [ ] Implement or find optimal baseline (use Concorde)
# - [ ] How does the Python object system work?
# - [ ] Try generating data from a different distribution than U([0, 1]^2)
# - [ ] Fun: pure C implementation
# - [ ] How do you get accuracy if your model is not a classifier?
#
# - each notebook is model_solver_dataset_loss
